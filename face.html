<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Camera with Face Detection</title>
    <style>
        body {
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            margin: 0;
            background-color: #f0f0f0;
            position: relative;
        }
        video, canvas {
            position: absolute;
            width: 100%;
            max-width: 600px;
            border: 5px solid #333;
            border-radius: 10px;
        }
    </style>
</head>
<body>

    <video id="video" autoplay playsinline muted></video>
    <canvas id="overlay"></canvas>

    <!-- Load face-api.js -->
    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>

    <script>
        const video = document.getElementById('video');

        // Load the models for face detection from the /models directory
        Promise.all([
            faceapi.nets.tinyFaceDetector.loadFromUri('models'),
            faceapi.nets.faceLandmark68Net.loadFromUri('models')
        ]).then(startVideo).catch(err => console.error('Model loading error:', err));

        // Function to start the video stream
        function startVideo() {
            if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
                navigator.mediaDevices.getUserMedia({ video: true })
                    .then(stream => {
                        video.srcObject = stream;
                        video.play();
                    })
                    .catch(err => {
                        console.error("Error accessing the camera: ", err);
                        alert("Error accessing the camera. Make sure camera permissions are granted.");
                    });
            } else {
                alert("getUserMedia not supported on this browser.");
            }
        }

        // Event listener to detect faces when the video starts playing
        video.addEventListener('play', () => {
            const canvas = faceapi.createCanvasFromMedia(video);
            document.body.append(canvas);

            const displaySize = { width: video.width, height: video.height };
            faceapi.matchDimensions(canvas, displaySize);

            setInterval(async () => {
                const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks();
                const resizedDetections = faceapi.resizeResults(detections, displaySize);

                canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
                faceapi.draw.drawDetections(canvas, resizedDetections);
                faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);
            }, 100);
        });
    </script>

</body>
</html>
